---
subtitle: "Achter Termin"
---

# Einstieg

## Zur Erinnerung

-   :computer: Arbeiten Sie aktiv mit.

-   :raising_hand: Stellen Sie Fragen.

-   :muscle: <https://tweedback.de/xxx/>

::: center
{{< qrcode https://tweedback.de/xxx/quiz width=400 height=400 >}}
:::

## Tipps f√ºr den Vorlesungserfolg

-   Kommen Sie zur Vorlesung!

-   Vermeiden Sie Ablenkung.

-   Arbeiten Sie die Vorlesung von Anfang an **vor** und nach. Nutzen Sie daf√ºr das Dokument *Quantitative Datenanalyse -- Umsetzung mit R*.

-   Stellen Sie Fragen.

-   Unterst√ºtzen Sie sich gegenseitig.

# R√ºckblick

## Beim letzen Mal haben Sie gelernt, dass...

-   kausale Beziehungen mit drei Variablen (X, Y und C) als **Chain**, **Fork** und **Inverted Fork** dargestellt werden k√∂nnen.

<!-- -->

-   das C in der **Chain** auch **Mediator** genannt werden kann und erkl√§rt, warum ein Effekt zwischen X und Y eintritt.

-   das C in der **Fork** ein sogenannter **Confounder** ist und einen Einfluss auf sowohl X als auch Y hat.

-   das C in der **Inverted Fork** ein **Collider** ist und von X und Y beeinflusst wird.

-   ein **Bias** eine systematische Verzerrung in den Daten / im Modell beschreibt und dass es unterschiedliche Arten dieser Verzerrungen gibt (Omitted-Variable-Bias, Collider-Bias, Sample-Selection-Bias, etc.).

## Heutiges Thema üè´

-   **Random Forest**

::: center
![](img/Memes/Random_Forest_Meme.gif){width="60%"}
:::

## Was Sie lernen üë©‚Äçüè´

-   Sie lernen, was ein Entscheidungsbaum ist, wie er funktioniert und f√ºr welche Datentypen dieser verwendet werden kann.

-   Sie lernen, was der Random-Forest-Algorithmus ist, was dieser mit Entscheidungsb√§umen zu tun hat und wie der Algorithmus funktioniert.

-   Sie lernen, wie der Random-Forest-Algorithmus trainiert, optimiert und getestet wird.

-   Sie lernen, f√ºr welche Probleme die Verwendung von Random Forest sinnvoll ist und sind in der Lage die Ergebnisse zu interpretieren.

## Entscheidungsbaum
:::center
Ein Entscheidungsbaum basiert auf der Idee komplexe Beziehungen, mithilfe von Daten, in einfache "ja/nein"-Fragen aufzubrechen.
:::

<br>

::::: columns
:::{.column width="50%"}
Die Struktur eines Entscheidungsbaumes ergibt sich dabei wie folgt:

An jedem Knotenpunkt (Node), beginnend mit der Wurzel des Baumes (Root Node), splittet der Entscheidungsbaum die Beobachtungen der Zielvariable (abh√§ngige Variable) anhand der Pr√§diktorvariablen (unabh√§ngige Variablen) in jeweils zwei Submengen. Dieser Vorgang wiederholt sich so lange, bis ein zuvor definiertes Abbruchkriterium erreicht wird. 
:::

:::{.column width="50%"}
:::center
![https://medium.com/analytics-vidhya/decision-trees-on-mark-need-why-when-quick-hands-on-conclude-ce10dac51e3](img/Sonstige/Decision_Tree.webp){width="70%"}
:::
:::
:::::

## CART-Algorithmus

Es k√∂nnen zwei Arten von Entscheidungsb√§umen unterschieden werden, Klassifikations- und Regressionsb√§ume (**C**lassification- **a**nd **R**egression **T**rees - CART).

- **Klassifikationsb√§ume** werden zur Vorhersage einer kategorialen Zielvariablen verwendet, 

\ \ \ \ w√§hrend<br>

- **Regressionsb√§ume** zur Vorhersage einer metrischen Zielvariablen eingesetzt werden.  

Der CART-Algorithmus ist nur eine von vielen Methoden, um Entscheidungsb√§ume zu erzeugen, sie ist aber die Grundlage f√ºr viele baumbasierte Machine-Learning-Algorithmen wie Random Forest.


## Entscheidungsbaum &ndash; Beispiel

![Quelle: eigene Darstellung](img/Sonstige/Beispiel-Klassifikationsbaum.png)

##

:::center
![](img/Memes/Decision_Tree_Random_Forrest_Meme.jpg){width="40%"}
:::

## Random Forest (I/II)

Random Forest ([Breiman, 2001](https://link.springer.com/article/10.1023/A:1010933404324)) ist ein Machine-Learning-Algorithmus, der die Ergebnisse vieler verschiedener Entscheidungsb√§ume kombiniert, um bestm√∂gliche Vorhersagen zu treffen.

- Dazu wird ein Datensatz in Test- und Trainingsdatensatz geteilt.
- Die einzelnen Entscheidungsb√§ume werden jeweils auf leicht verschiedenen Subdatens√§tzen des Trainingsdatensatzes trainiert.
- Diese verschiedenen Subdatens√§tze werden mithilfe von *Bootstrap Sampling* erstellt. <br>
\ \ \ \ \ **&rarr;** Bootstrap Sampling funktioniert indem eine festgelegte Menge von Bootstrap-Stichproben <br> 
\ \ \ \ \ \ \ (d.h. Stichproben der gleichen Gr√∂√üe) durch zuf√§lliges Ziehen von Beobachtungen mit <br>
\ \ \ \ \ \ \ Zur√ºcklegen aus dem Trainigsdatensatz generiert werden.

- Damit die Entscheidungsb√§ume noch verschiedener zueinander werden, verwendet der Algorithmus f√ºr jeden einzelnen Split des B√§ume eine zuf√§llige Teilmenge der Variablen des Subdatensatzes.  

## Random Forest (II/II)

<br>
Zusammenfassend l√§sst sich sagten, dass die einzelnen Entscheidungsb√§ume auf zuf√§llig zusammengesetzten Subdatens√§tzen, die bei jedem Split eine neue, zuf√§llige Zusammensetzung von Variablen besitzen, erstellt werden.

<br> 

- Die einzelnen Entscheidungsb√§ume werden am Ende des Algorithmus zusammengefasst (*Aggregation*) und geben ein Modell zur√ºck, mit dem neue Werte vorhergesagt werden k√∂nnen. <br>
\ \ \ \ \ **&rarr;** Je nach Zielvariable (Regression oder Klassifikation) wird entweder der Durchschnitt oder die
\ \ \ \ \ \ \ Mehrheit der Vorhersagen verwendet, um genauere Vorhersagen zu treffen.


## RF-Algorithmus

:::center
![](img/Sonstige/RF-Algorithmus.png){width="71%"}
:::
:::footnote
Quelle: eigene Darstellung
:::

## Zusammenfassung

-   **Entscheidungsbaum:** Ein grafisches Modell, das Entscheidungen und deren m√∂gliche Konsequenzen in Form von verzweigten Pfaden darstellt, wobei jeder Knoten eine Entscheidungsregel und jedes Blatt ein Ergebnis repr√§sentiert.

-   **Random Forest:** Ein Machine-Learning-Algorithmus, der eine Vielzahl von Entscheidungsb√§umen kombiniert, um durch Mehrheitsvotings oder Mittelung stabilere und bessere Vorhersagen zu treffen.

::: center
![](img/Sonstige/DecisionTree_RandomForest.webp){width="40%"}
:::

## Fallstudie üíª

::::::: columns
:::: {.column width="50%"}
-   posit Cloud: In **Ihr** Projekt einloggen.

::: center
![](img/Software/posit_Project_StatistischeModellierung.png){width="80%"}
:::
::::

:::: {.column width="50%"}
-   Lokal: RStudio durch Klick auf `StatMod_WiSe24.Rproj` starten oder RStudio aufrufen, das letzte Projekt m√ºsste automatisch geladen werden.

::: center
![](img/Software/RStudio_Project_StatistischeModellierung.png){width="60%"}
:::
::::
:::::::

√ñffnen Sie die Datei `Random-Forest.qmd` im Ordner `fallstudien`.
