---
subtitle: "Achter Termin"
---

# Einstieg

## Zur Erinnerung

-   :computer: Arbeiten Sie aktiv mit.

-   :raising_hand: Stellen Sie Fragen.

-   :muscle: <https://tweedback.de/xxx/>

::: center
{{< qrcode https://tweedback.de/xxx/quiz width=400 height=400 >}}
:::

## Tipps f√ºr den Vorlesungserfolg

-   Kommen Sie zur Vorlesung!

-   Vermeiden Sie Ablenkung.

-   Arbeiten Sie die Vorlesung von Anfang an **vor** und nach. Nutzen Sie daf√ºr das Dokument *Quantitative Datenanalyse -- Umsetzung mit R*.

-   Stellen Sie Fragen.

-   Unterst√ºtzen Sie sich gegenseitig.

# R√ºckblick

## Beim letzen Mal haben Sie gelernt, dass...

-   kausale Beziehungen mit drei Variablen (X, Y und C) als **Chain**, **Fork** und **Inverted Fork** dargestellt werden k√∂nnen.

<!-- -->

-   das C in der **Chain** auch **Mediator** genannt werden kann und erkl√§rt, warum ein Effekt zwischen X und Y eintritt.

-   das C in der **Fork** ein sogenannter **Confounder** ist und einen Einfluss auf sowohl X als auch Y hat.

-   das C in der **Inverted Fork** ein **Collider** ist und von X und Y beeinflusst wird.

-   ein **Bias** eine systematische Verzerrung in den Daten / im Modell beschreibt und dass es unterschiedliche Arten dieser Verzerrungen gibt (Omitted-Variable-Bias, Collider-Bias, Sample-Selection-Bias, etc.).

## Heutiges Thema üè´

-   **Random Forest**

::: center
![](img/Memes/Random_Forest_Meme.gif){width="60%"}
:::

## Was Sie lernen üë©‚Äçüè´

-   Sie lernen, was ein Entscheidungsbaum ist, wie er funktioniert und f√ºr welche Datentypen dieser verwendet werden kann.

-   Sie lernen, was der Random-Forest-Algorithmus ist, was dieser mit Entscheidungsb√§umen zu tun hat und wie der Algorithmus funktioniert.

-   Sie lernen, wie der Random-Forest-Algorithmus trainiert, optimiert und getestet wird.

-   Sie lernen, f√ºr welche Probleme die Verwendung von Random Forest sinnvoll ist und sind in der Lage die Ergebnisse zu interpretieren.

## Entscheidungsbaum
:::center
Ein Entscheidungsbaum basiert auf der Idee komplexe Beziehungen, mithilfe von Daten, in einfache "ja/nein"-Fragen aufzubrechen.
:::

<br>

::::: columns
:::{.column width="50%"}
Die Struktur eines Entscheidungsbaumes ergibt sich dabei wie folgt:

An jedem Knotenpunkt (Node), beginnend mit der Wurzel des Baumes (Root Node), splittet der Entscheidungsbaum die Beobachtungen der Zielvariable (abh√§ngige Variable) anhand der Pr√§diktorvariablen (unabh√§ngige Variablen) in jeweils zwei Submengen. Dieser Vorgang wiederholt sich so lange, bis ein zuvor definiertes Abbruchkriterium erreicht wird. 
:::

:::{.column width="50%"}
:::center
![Quelle: https://medium.com/analytics-vidhya/decision-trees-on-mark-need-why-when-quick-hands-on-conclude-ce10dac51e3](img/Sonstige/Decision_Tree.webp){width="70%"}
:::
:::
:::::

## CART-Algorithmus

Es k√∂nnen zwei Arten von Entscheidungsb√§umen unterschieden werden, Klassifikations- und Regressionsb√§ume (**C**lassification- **a**nd **R**egression **T**rees - CART).

- **Klassifikationsb√§ume** werden zur Vorhersage einer kategorialen Zielvariablen verwendet, 

\ \ \ \ w√§hrend<br>

- **Regressionsb√§ume** zur Vorhersage einer metrischen Zielvariablen eingesetzt werden.  

Der CART-Algorithmus ist nur eine von vielen Methoden, um Entscheidungsb√§ume zu erzeugen, sie ist aber die Grundlage f√ºr viele baumbasierte Machine-Learning-Algorithmen wie Random Forest.


## Entscheidungsbaum &ndash; Beispiel

![Quelle: eigene Darstellung](img/Sonstige/Beispiel-Klassifikationsbaum.png)

##

:::center
![](img/Memes/Decision_Tree_Random_Forrest_Meme.jpg){width="40%"}
:::

## Random Forest (I/II)

Random Forest ([Breiman, 2001](https://link.springer.com/article/10.1023/A:1010933404324)) ist ein Machine-Learning-Algorithmus, der die Ergebnisse vieler verschiedener Entscheidungsb√§ume kombiniert, um bestm√∂gliche Vorhersagen zu treffen.

- Dazu wird ein Datensatz in Test- und Trainingsdatensatz geteilt.
- Die einzelnen Entscheidungsb√§ume werden jeweils auf leicht verschiedenen Subdatens√§tzen des Trainingsdatensatzes trainiert.
- Diese verschiedenen Subdatens√§tze werden mithilfe von *Bootstrap Sampling* erstellt.
    -   Bootstrap Sampling funktioniert, indem eine festgelegte Menge von Bootstrap-Stichproben 
(d.¬†h. Stichproben der gleichen Gr√∂√üe) durch zuf√§lliges Ziehen von Beobachtungen mit Zur√ºcklegen aus dem Trainigsdatensatz generiert werden.

- Damit die Entscheidungsb√§ume noch verschiedener zueinander werden, verwendet der Algorithmus f√ºr jeden einzelnen Split der B√§ume eine zuf√§llige Teilmenge der Variablen des Subdatensatzes.  

## Random Forest (II/II)

-   Zusammenfassend l√§sst sich sagen, dass die einzelnen Entscheidungsb√§ume auf zuf√§llig zusammengesetzten Subdatens√§tzen, die bei jedem Split eine neue, zuf√§llige Zusammensetzung von Variablen besitzen, erstellt werden.

- Die einzelnen Entscheidungsb√§ume werden am Ende des Algorithmus zusammengefasst (*Aggregation*) und geben ein Modell zur√ºck, mit dem neue Werte vorhergesagt werden k√∂nnen. 

-   Je nach Zielvariable (Regression oder Klassifikation) wird entweder der Durchschnitt oder die Mehrheit der Vorhersagen verwendet, um genauere Vorhersagen zu treffen.


## RF-Algorithmus

:::center
![](img/Sonstige/RF-Algorithmus.png){width="71%"}
:::
:::footnote
Quelle: eigene Darstellung
:::

## Zusammenfassung

-   **Entscheidungsbaum:** Ein grafisches Modell, das Entscheidungen und deren m√∂gliche Konsequenzen in Form von verzweigten Pfaden darstellt, wobei jeder Knoten eine Entscheidungsregel und jedes Blatt ein Ergebnis repr√§sentiert.

-   **Random Forest:** Ein Machine-Learning-Algorithmus, der eine Vielzahl von Entscheidungsb√§umen kombiniert, um durch Mehrheitsvotings oder Mittelung stabilere und bessere Vorhersagen zu treffen.

::: center
![](img/Sonstige/DecisionTree_RandomForest.webp){width="40%"}
:::

:::footnote
Quelle: [https://blog.dailydoseofds.com/p/your-random-forest-is-underperforming](https://blog.dailydoseofds.com/p/your-random-forest-is-underperforming)
:::
## Beispiel

```{r}
costumer <- read.csv2("internaldata/RF_CostumerSegmentation.csv")
costumer$Segmentation <- as.factor(costumer$Segmentation)

library(mosaic)
library(randomForest)
library(caret)
library(tidyverse)
```

::::: columns
:::{.column width="70%"}

Ein Automobilunternehmen plant, mit bestehenden Produkten (P1, P2, P3, P4 und P5) in neue M√§rkte einzutreten. 

In ihrem aktuellen Markt hat das Vertriebsteam alle Kunden in vier Segmente (A, B, C, D) eingeteilt und f√ºr jedes Kundensegment gezielte Ansprache- und Kommunikationsstrategien entwickelt. Diese Strategie hat sich als √§u√üerst erfolgreich erwiesen.
:::

:::{.column width="30%"}
::: center
![](img/Sonstige/Costumer.png){width="80%"}
:::
:::
:::::

Nun plant das Unternehmen, dieselbe Strategie f√ºr neue M√§rkte anzuwenden. Nach intensiver Marktforschung haben sie festgestellt, dass das Verhalten neuer M√§rkte dem ihres bestehenden Marktes √§hnelt. Wie gut eignet sich Random Forest um die Kunden des neuen Marktes in die vier Segmente einzuteilen?

```{webr-r}
#| autorun: true
costumer <- read.csv2("https://raw.githubusercontent.com/FOM-ifes/variousdata/refs/heads/main/RF_CostumerSegmentation.csv")

# Abh√§ngige Variable zu Faktor kodieren, damit randomForest() mit der Variable umgehen kann
costumer$Segmentation <- as.factor(costumer$Segmentation)
```

:::footnote
Die Daten und das Bild stammen von [Kaggle](https://www.kaggle.com/datasets/kaushiksuresh147/customer-segmentation). Im Vorhinein wurden alle Zeilen mit fehlenden Werten entfernt und der Trainings- und Testdatensatz zusammengefasst.
:::

## Split in Trainings- und Testdatensatz

Die Teilung der Daten erlaubt es, die Leistung des Random-Forest-Algorithmus zu bewerten, indem der Algorithmus nach dem Training auf unbekannte Daten zur Evaluation der Generalisierbarkeit des Modells angewendet wird.


```{webr-r}
dim(costumer)
```

Hier werden zuf√§llig 80¬†% der Beobachtungen des urspr√ºnglichen Datensatzes in den Trainigsdatensatz gezogen und die restlichen 20¬†% bilden den Testdatensatz:


```{webr-r}
#| label: trainings-test-data
#| autorun: true
#| output: false
library(caret)

# Datenaufteilung in Trainings- und Testdaten
set.seed(42)
trainIndex <- createDataPartition(costumer$Segmentation, p = 0.8, list = FALSE)
trainData <- costumer[trainIndex, ]
testData <- costumer[-trainIndex, ]
```

```{r}
set.seed(42)
trainIndex <- createDataPartition(costumer$Segmentation, p = 0.8, list = FALSE)
trainData <- costumer[trainIndex, ]
testData <- costumer[-trainIndex, ]
```

::::: columns
::: {.column width="50%"}

```{webr-r}
# √úberblick √ºber Trainingsdaten:
dim(trainData)
```

:::

:::: {.column width="50%"}

```{webr-r}
# √úberblick √ºber Testdaten:
dim(testData)
```

:::
:::::

## Trainieren des RF-Modells

Das Trainieren des Modells erm√∂glicht dem Random-Forest-Algorithmus Muster in den Daten zu erkennen:

```{webr-r}
#| label: train-the-model
library(randomForest)

# Training des Random Forest Modells
set.seed(42)
rf_model1 <- randomForest(Segmentation ~ ., data = trainData, 
                          importance = TRUE)
```

```{r}
set.seed(42)
rf_model1 <- randomForest(Segmentation ~ ., data = trainData, 
                          importance = TRUE)
```

```{webr-r}
# √úberblick √ºber das Modell
rf_model1
```


## Testen des RF-Modells

Im vorherigen Schritt hatte das Modell die M√∂glichkeit, anhand des Trainingsdatensatzes Muster und Zusammenh√§nge in den Daten zu erkennen und zu lernen. Wie gut das dem Modell gelungen ist, kann √ºberpr√ºft werden, indem das Modell auf unbekannte Daten (Testdaten) zur Vorhersage angewendet wird:

```{r}
observed <- testData$Segmentation
predicted <- predict(rf_model1, testData)
```

```{webr-r}
# Definition der beobachteten Werte
observed <- testData$Segmentation

# Vorhersage auf den Testdaten
predicted <- predict(rf_model1, testData)
head(predicted)
```

```{webr-r}
# Wahre Werte auf den Testdaten
head(testData$Segmentation)
```


## Tuning des Modells (I/II)

Anhand der Ergebnisse des Modells erkennt man, dass die Vorhersagen nicht in allen F√§llen korrekt waren. Eine vollst√§ndige √úbereinstimmung mit den tats√§chlichen Werten ist zwar unwahrscheinlich, jedoch k√∂nnen sog. Hyperparameter des RF-Algorithmus optimiert werden, um die Vorhersagegenauigkeit zu verbessern.

Zu diesen Hyperparametern z√§hlen unter anderem:

- `ntree:` gibt die Anzahl der Entscheigungsb√§ume im RF an.
Die Voreinstellung (default) ist 500.
- `mtry:` gibt die Anzahl der zuf√§llig ausgew√§hlten Pr√§diktorvariablen an jedem Split an.

Standardm√§√üig ist `mtry` auf $\sqrt{p}$ bei der Klassifikation und auf $\frac{p}{3}$ bei der Regression gesetzt -- $p$ ist hier die Anzahl der Pr√§diktorvariablen.

Die Voreinstellung f√ºr die Anzahl der Entscheidungsb√§ume im Modell liegt bei `ntree = 500`.

<br>

:::footnote
*Hinweis: F√ºr beide Hyperparameter gilt, wenn das Modell mit den Standardeinstellungen trainiert werden soll, dann m√ºssen die Parameter in der randomForest()-Funktion nicht n√§her spezifiziert werden.*
:::

## Tuning des Modells (II/II)

Bei der Rastersuche (grid search) werden alle m√∂glichen Kombinationen der angegebenen Hyperparameterwerte ausprobiert, um das beste Modell zu finden.
Das beste Modell findet der RF-Algorithmus mit Hilfe der Kreuzvalidierung (`method = "cv"`):

```{r}
# control <- trainControl(method = "cv", number = 5)
# tuneGrid <- expand.grid(.mtry = c(2, 4, 6, 8, 10))
# 
# set.seed(42)
# rf_tuned <- train(Segmentation ~ ., data = trainData, method = "rf", 
#                   trControl = control, tuneGrid = tuneGrid)

load("internaldata/RF_tuned.RData")

```

:::footnote
Der Code zum Tuning des Modells ist schon durchgelaufen und muss nicht nochmal ausgef√ºhrt werden!
:::
```{webr-r}
#| autorun: true
#| output: false
library(randomForest)

control <- trainControl(method = "cv", number = 5)
tuneGrid <- expand.grid(.mtry = c(2, 4, 6, 8, 10))

set.seed(42)
rf_tuned <- train(Segmentation ~ ., data = trainData, method = "rf", 
                  trControl = control, tuneGrid = tuneGrid)
```

```{webr-r}
best_mtry <- rf_tuned$bestTune$mtry
best_mtry
```

```{webr-r}
predicted_tuned <- predict(rf_tuned, testData)
head(predicted_tuned)
```


## Vergleich der Modellg√ºte (I/II)

H√§ufig verwendete Modellg√ºtekriterien f√ºr die Klassifikation sind:

**Accuracy**: Verh√§ltnis von korrekt vorhergesagten Werten zur Gesamtzahl aller Vorhersagen

$$ Accuracy = \frac{korrekte \ Vorhersagen}{Gesamtzahl \ der \ Vorhersagen}$$

**Cohen's Kappa**: Funktioniert √§hnlich zur Accuracy, ber√ºcksichtigt jedoch, wie viele korrekte Vorhersagen auch zuf√§llig entstehen k√∂nnten.

$$ Kappa = \frac{p_o - p_e}{1 - p_e}$$
wobei:

::: {style="font-size: 90%;"}

- $p_o$: beobachtete √úbereinstimmung (Anteil der F√§lle, bei denen das Modell die richtige Klasse vorhergesagt hat)
- $p_e$: erwartete √úbereinstimmung (Zufalls√ºbereinstimmung basierend auf den Randh√§ufigkeiten der Klassen)

:::


## Vergleich der Modellg√ºte (II/II)

Zum Abschluss kann mithilfe verschiedener Modellg√ºtekriterien verglichen werden, welches der beiden Modelle (Ursprungsmodell und getuntes Modell) besser performt hat.

<br>

::::: columns
::: {.column width="50%"}
```{webr-r}
# Ursprungsmodell
postResample(pred = predicted, obs = observed)
```
:::

::: {.column width="50%"}
```{webr-r}
# Getuntes Modell
postResample(pred = predicted_tuned, obs = observed)
```
:::
:::::


## Fallstudie üíª

::::::: columns
:::: {.column width="50%"}
-   posit Cloud: In **Ihr** Projekt einloggen.

::: center
![](img/Software/posit_Project_StatistischeModellierung.png){width="80%"}
:::
::::

:::: {.column width="50%"}
-   Lokal: RStudio durch Klick auf `StatMod_WiSe25.Rproj` starten oder RStudio aufrufen, das letzte Projekt m√ºsste automatisch geladen werden.

::: center
![](img/Software/RStudio_Project_StatistischeModellierung.png){width="60%"}
:::
::::
:::::::

√ñffnen Sie die Datei `Random-Forest.qmd` im Ordner `fallstudien`.
