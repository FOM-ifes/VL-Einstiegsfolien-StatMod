---
subtitle: "F√ºnfter Termin"
---

# Einstieg

## Zur Erinnerung

-   :computer: Arbeiten Sie aktiv mit.

-   :raising_hand: Stellen Sie Fragen.

-   :muscle: <https://tweedback.de/xxx/>

::: center
{{< qrcode https://tweedback.de/xxx/quiz width=400 height=400 >}}
:::

## Tipps f√ºr den Vorlesungserfolg

-   Kommen Sie zur Vorlesung!

-   Vermeiden Sie Ablenkung.

-   Arbeiten Sie die Vorlesung von Anfang an **vor** und nach. Nutzen Sie daf√ºr das Dokument *Quantitative Datenanalyse -- Umsetzung mit R*.

-   Stellen Sie Fragen.

-   Unterst√ºtzen Sie sich gegenseitig.

# R√ºckblick

## Was beim letzten Mal geschah ...

-   Sie haben die Bayes'sche Denkweise kennengelernt.

-   Sie k√∂nnen zwei Wahrscheinlichkeiten unterscheiden: epistemische und aleatorische Wahrscheinlichkeit.

-   Sie kennen den Satz von Bayes.

-   Sie wissen, was die Priori-Verteilung ist - die Wahrscheinlichkeitsverteilung von $\pi$, bevor wir unsere Daten haben.

-   Sie wissen, was die Likelihood ist - die Mutma√ülichkeit von $p$ bei gegebenem $\pi$.

-   Sie wissen, was die Posteriori-Verteilung ist - die Wahrscheinlichkeitsverteilung von $\pi$, nachdem wir unsere Daten haben.

-   Sie k√∂nnen die Priori-Verteilung, die Likelihood und damit die Posteriori-Verteilung bestimmen.

## ... und ...

-   Sie wissen, dass die Beta-Verteilung die Grundlage f√ºr die Priori- und die Posteriori-Verteilung ist.

-   Sie k√∂nnen $\alpha$ und $\beta$ als Parameter der Beta-Verteilung bestimmen.

-   Sie k√∂nnen den Erwartungswert und die Varianz der Beta-Verteilung berechnen und visualisieren.

-   Sie wissen, dass die Binomialverteilung mit den Parametern $n$ und $\pi$ die Grundlage der Likelihood ist.

-   Sie k√∂nnen die Verteilung der Likelihood bestimmen.

## Heutiges Thema üè´

-   Wiederholung Regression

## Was Sie lernen üë©‚Äçüè´

-   Sie wenden die lineare Regression mit einer oder mehreren unabh√§ngigen Variablen an (univariate vs. multivariate Regressionsmodelle).

-   Sie k√∂nnen die Koeffizienten zu unterschiedlich skalierten unabh√§ngigen Variablen interpretieren.

-   Sie k√∂nnen das Bestimmtheitsma√ü $R^2$ interpretieren.

-   Sie k√∂nnen zwischen verschiedenen Regressionsmodellen ausw√§hlen.

## Schlagen Sie die ü§ñ?

Mission Vorhersage üëâ <https://fomshinyapps.shinyapps.io/Regressioncontest/>

<!-- Ggf. bit.ly-Link und -QR-Code -->

::: center
![](img/Sonstige/linearregression.png){width="50%"}
:::

## You can't beat ü§ñ

<br>

::: center
ü•á 4698,928 ü•á
:::

$$Verbrauch = 8.120,60 - 18,44 \cdot Temperatur$$

## Regression motivieren

-   Stellen Sie sich eine Regressionsanalyse wie eine Radiostation vor, die ein Programm sendet.

-   Man empf√§ngt dieses *Signal* nur weit entfernt -- mit *Rauschen*. Das, was man empf√§ngt, setzt sich also aus *Signal* und *Rauschen* zusammen.

-   Es gibt diverse Techniken, um aus dem Empfangenen m√∂glichst das gesendete Signal zu extrahieren und gleichzeitig das Rauschen zu reduzieren.

^Anregung:¬†[Tay¬†(2022)](https://doi.org/10.1080/26939169.2021.2024777)^

-   Regression funktioniert genau so: Es lagen (fiktive) Daten von Temperatur und Vebrauch vor und es soll der Zusammenhang zwischen diesen Variablen analysiert werden.
-   Das gefundene Modell wird aufgrund des Rauschens nicht perfekt sein.


## Einfaches lineares Modell

Modelliere den Wert einer [abh√§ngigen]{.olive} metrischen Variable als **lineare** Funktion einer [unabh√§ngigen]{.purple} Variable, $\color{olive} {y} = f(\color{purple} {x}) + \color{orange} {\epsilon}$:

$$\color{olive} {y_i} = \color{violet} {\beta_0} + \color{blue} {\beta_1} \cdot \color{purple} {x_i} + \color{orange} {\epsilon_i} $$

Mit: 

- $\color{violet} {\beta_0}$: $y$-Achsenabschnitt im theoretischen Modell der Population,
- $\color{blue} {\beta_1}$: Steigung im theoretischen Modell der Population,
- $\color{orange} \epsilon$: Fehlerterm (*Rest*).

Im Modell der Stichprobe beschreiben $\color{violet} {b_0}, \color{blue} {b_1}$ den linearen Zusammenhang:
$$\color{olive} {y_i} = \color{violet} {b_0} + \color{blue} {b_1} \cdot \color{purple} {x_i} + \color{orange} {e_i} $$

## Kleinste Quadrate Methode

::::: columns
::: {.column width="50%"}

<br>

Ziel der KQ-Methode ist es die Quadratsumme der Residuen  $\color{orange} {e_i}=\color{olive} {y_i}- \color{olive} {\hat{y}_i}$zu minimieren: $$\min\sum_i{\color{orange} {e_i}^2}$$

D.h., dass der **modellierte** Wert $\color{olive} {\hat{y}_i}$ der abh√§ngigen Variable √ºber alle Beobachtungen $i$ m√∂glichst nah am **beobachteten** Wert $\color{olive} {y_i}$ liegen soll.
:::

::: {.column width="50%"}

::: center
![](img/Sonstige/RegressionRSS.gif){width="90%"}
:::

:::
:::::


## Bestimmtheitsma√ü

Das Bestimmtheitsma√ü $R^2$ gibt den Anteil der im Modell erkl√§reten Variation von $y$ an:

$$R^2 = \frac{\sum_{i=1}^n (\hat{y}_i-\bar{y})^2}{\sum_{i=1}^n (y_i-\bar{y})^2} = 1-\frac{\sum_{i=1}^n (y_i-\hat{y}_i)^2}{\sum_{i=1}^n (y_i-\bar{y})^2}$$

-   *Einfachstes Modell*: Prognose durch Mittelwert: $\hat{y}_i = \bar{y} : R^2 = 0$
-   *Bestes Modell*: Prognose ist Beobachtung: $\hat{y}_i = \bar{y} : R^2 = 1$

::: center
![](img/Sonstige/R-Quadrat.png){width="42%"}
:::


## Inferenz in der Regression

::: center
$$\hat{\beta} = \beta + \text{(Verzerrung)} + \text{Rauschen}$$

![Quelle: [David Hood](https://twitter.com/Thoughtfulnz/status/1446972794135216131)](img/Memes/modelmeme.jpeg){fig-align="center" width="60%"}
:::

##Sch√§tzunsicherheit

::::: columns
::: {.column width="48%"}
**Resampling**:

- Unterscheiden sich die Stichproben, k√∂nnen sich auch die Ergebnisse (leicht) unterscheiden.
- Diese Unsicherheit durch die Variation der Stichprobe k√∂nnen wir simulieren, indem wir aus unserer Stichprobe eine neue ziehen.
- Durch **Ziehen mit Zur√ºcklegen (resampling)** kann eine neue, zuf√§llige Stichprobe aus den vorhandenen Daten gewonnen werden.

:::

::: {.column width="50%"}
**Bootstrapping**:

- Den wiederholten Vorgang des Resamplings nennt man Bootstrapping.
- Voraussetzungen f√ºr das Bootstrapping sind:
  + Zuf√§llige Stichprobe oder zuf√§llige Zuordnung
  + Nicht zu kleine Stichprobe ($n \geq 35$)

:::
:::::

## Schema: Bootstrapping

:::center
![](img/Sonstige/Schema_Bootstrap.png){width="80%"}
:::

:::footnote
Quelle:
:::


## Schema der simulationsbasierten Inferenz

:::center
![](img/Sonstige/Schema_Simulation.png){width="80%"}
:::

:::footnote
Quelle: [Blogbeitrag Allen Downey](http://allendowney.blogspot.de/2016/06/there-is-still-only-one-test.html)
:::


## Standardfehler

Der Standardfehler (engl.: "**standard error**" oder **se**) ist ein Ma√ü daf√ºr, wie stark eine Zusammenfassung der Stichprobe &ndash; ein Sch√§tzwert &ndash; (z.¬†B. der Mittelwert oder Anteilswert) vom wahren, unbekannten Wert der Population abweicht. Je gr√∂√üer die Stichprobe ($n$), desto kleiner der Standardfehler:

::: {layout-ncol=2}
$$ se = \frac{sd}{\sqrt{n}} $$

$$se_p=\sqrt{\frac{\pi\cdot(1-\pi)}{n}}$$
:::

<br>

[Nicht]{.red} zu verwechseln mit der **Standardabweichung**: Die **Standardabweichung** ist ein Ma√ü f√ºr die Streuung der Beobachtungen, das hei√üt wie gleich oder verschiedenartig die Beobachtungen in der Stichprobe sind.


## Konfidenzintervall

Ein **Konfidenzintervall** gibt einen Bereich an, der den wahren, unbekannten Wert der Population mit einer gegebenen Sicherheit ($1 - Irrtumswahrscheinlichkeit \ (\alpha)$) √ºberdeckt, d.¬†h., den Anteil der so konstruierten Konfidenzintervalle, die den Wert enthalten. F√ºr den Stichprobenmittelwert ergeben sich folgende Grenzen (Bsp. Mittelwert):

$$ KI = \bar{x} \pm z_{(1 - \frac{\alpha}{2})} \cdot se = \bar{x} \pm z_{(1 - \frac{\alpha}{2})} \frac{sd}{\sqrt{n}}$$

- wobei $z_{(1 - \frac{\alpha}{2})}$ nach der 68-95-99.7%-Regel bestimmt werden kann (z.¬†B. bei 95% ist $z_{(1 - \frac{0,5}{2})} \approx 2$)

- Je gr√∂√üer der Stichprobenumfang, desto schmaler das Konfidenzintervall (unter sonst gleichen Umst√§nden): Der Standardfehler $se$ f√§llt mit steigendem $n$.

- Je gr√∂√üer die Sicherheit(z.¬†B. 99% statt 95%), desto breiter das Intervall.


## p-Wert

Der **p-Wert** gibt den Anteil der Stichproben an, die ein mindestens genau so extremes Ergebnis wie die beobachtete Sichprobe aufweisen, unter der Annahme, dass die $H_0$ gilt.

Anders gesagt: Der p-Wert berechnet sich als die Wahrscheinlichkeit eines solchen oder extremeren Wertes der Teststatistik unter den Annahmen von $H_0$.

[Achtung:]{.red} Der p-Wert sagt nicht aus, wie wahrscheinlich die $H_0$ bei den vorliegenden Daten (Teststatistik) ist!

<br>
**Testentscheidung**: <br>
**Keine** Entscheidung sollte rein auf Basis den p-Wertes getroffen werden, *vor* der Testentscheidung ist **immer** eine explorative Datenanalyse durchzuf√ºhren.

- Ist der p-Wert $< \alpha$, so wird $H_{0}$ verworfen, ansonsten nicht.
- Wird die $H_{0}$ verworfen, so nennt man das Ergebnis (statistisch) signifikant zum Niveau $\alpha$.


## Multiple Regression

<br>
Modellgleichung:

$${y_i} = {\beta_0} + {\beta_1} \cdot {x_{i1}} + {\beta_2} \cdot {x_{i2}} + ... + {\beta_p} \cdot {x_{ip}} + {\epsilon_i} $$
Interpretation der Koeffizienten (Sch√§tzwerte, p-Werte) unter Annhame sonst gleicher Umst√§nde, d.¬†h., die anderen Variablen im Modell bleiben konstant / unver√§ndert (ceteris paribus, c.¬†p.): marginaler Effekt.

<br>
[Wichtig:]{.red} Der Regressionskoeffizient ($\beta$) eines Pr√§diktors h√§ngt davon ab, welche anderen Pr√§diktoren in der multiplen Regression betrachtet werden. H√§ufig h√§ngen die Pr√§diktoren untereinander zusammen und kl√§ren teilweise die gleichen Varianzanteile des Kriteriums auf.


## Interaktionseffekte

<br>
Modellbeispiel:

$${y_i} = {\beta_0} + {\beta_1} \cdot {x_{i1}} + {\beta_1} \cdot {x_{i1}} + {\beta_3} \cdot ({x_{i1}} \cdot {x_{i2}}) + {\epsilon_i} $$
Hierbei ist $\beta_3$ der Koeffizient des Interaktionsterms $X_1 \cdot X_2$, der die zus√§tzlich Wirkung beschreibt, die nicht durch die einzelnen Effekte von $X_1$ und $X_2$ erkl√§rt wird.


## Fallstudie üíª

::::::: columns
:::: {.column width="50%"}
-   posit Cloud: In **Ihr** Projekt einloggen.

::: center
![](img/Software/posit_Project_StatistischeModellierung.png){width="80%"}
:::
::::

:::: {.column width="50%"}
-   Lokal: RStudio durch Klick auf `StatMod_WiSe24.Rproj` starten oder RStudio aufrufen, das letzte Projekt m√ºsste automatisch geladen werden.

::: center
![](img/Software/RStudio_Project_StatistischeModellierung.png){width="60%"}
:::
::::
:::::::

√ñffnen Sie die Datei `Immobilien.qmd` im Ordner `fallstudien`.
